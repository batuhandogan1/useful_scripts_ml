{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xywh2xyxy(size, box):\n",
    "        \"\"\"\n",
    "        Param:  self\n",
    "                +size: (Tuple)\n",
    "                +box: (Numpy array)\n",
    " \n",
    "        Using:  +size: (Tuple)\n",
    "                +box: (Numpy array)\n",
    " \n",
    "        Does:   Gets a numpy xywh Yolo format\n",
    "                array and transforms to x1y1x2y2  format.\n",
    "        \n",
    "        Return: (x1, y1, x2, y2)\n",
    "        \"\"\"\n",
    "        width, height = size\n",
    "        x_center, y_center, w, h = box\n",
    "        x1 = (x_center - w / 2) * width\n",
    "        y1 = (y_center - h / 2) * height\n",
    "        x2 = (x_center + w / 2) * width\n",
    "        y2 = (y_center + h / 2) * height\n",
    "        return (x1, y1, x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyxyx2xywh(size, box):\n",
    "        \"\"\"\n",
    "        Param:  self\n",
    "                +size: (Tuple)\n",
    "                +box: (Numpy array)\n",
    "\n",
    "        Using:  +size: (Tuple)\n",
    "                +box: (Numpy array)\n",
    "\n",
    "        Does:   Gets a numpy x1y1x2y2 array and\n",
    "                transforms to xywh YOLO format.\n",
    "        \n",
    "        Return: x, y, w, h\n",
    "        \"\"\"\n",
    "        img_width, img_height = size\n",
    "        x1, y1, x2, y2 = box\n",
    "\n",
    "        x_center = (x1 + x2) / 2.0\n",
    "        y_center = (y1 + y2) / 2.0\n",
    "        \n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        \n",
    "        x_center /= img_width\n",
    "        y_center /= img_height\n",
    "        width /= img_width\n",
    "        height /= img_height\n",
    "        \n",
    "        return x_center, y_center, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38d66bee_frame532\n",
      "38d66bee_frame5381\n",
      "38d66bee_frame5432\n",
      "38d66bee_frame5281\n",
      "38d66bee_frame113\n",
      "38d66bee_frame5330\n",
      "38d66bee_frame4664\n",
      "38d66bee_frame3779\n",
      "38d66bee_frame3925\n",
      "38d66bee_frame2690\n",
      "38d66bee_frame1535\n",
      "38d66bee_frame3780\n",
      "38d66bee_frame2018\n",
      "38d66bee_frame3782\n",
      "38d66bee_frame1318\n",
      "38d66bee_frame1835\n",
      "38d66bee_frame3294\n",
      "38d66bee_frame5415\n",
      "38d66bee_frame1749\n",
      "38d66bee_frame3781\n",
      "38d66bee_frame34\n",
      "38d66bee_frame3121\n",
      "38d66bee_frame3783\n",
      "38d66bee_frame2266\n",
      "38d66bee_frame1833\n",
      "38d66bee_frame1834\n",
      "38d66bee_frame112\n",
      "38d66bee_frame3122\n",
      "38d66bee_frame4662\n",
      "38d66bee_frame3041\n",
      "38d66bee_frame796\n",
      "38d66bee_frame3786\n",
      "38d66bee_frame346\n",
      "38d66bee_frame3784\n",
      "38d66bee_frame5414\n",
      "38d66bee_frame3785\n",
      "38d66bee_frame5231\n",
      "38d66bee_frame3968\n",
      "38d66bee_frame1319\n",
      "38d66bee_frame93\n",
      "38d66bee_frame5077\n",
      "38d66bee_frame2504\n",
      "38d66bee_frame3120\n",
      "38d66bee_frame1322\n",
      "38d66bee_frame3242\n"
     ]
    }
   ],
   "source": [
    "path = '/home/bdogan/Desktop/obj_train_data/'\n",
    "temp_destination = '/home/bdogan/Desktop/test/'\n",
    "ratio = 1.15\n",
    "\n",
    "files = os.listdir(path)\n",
    "\n",
    "for file in files:\n",
    "    if file.endswith('.jpg'):\n",
    "\n",
    "        temp = file.split('.jpg')\n",
    "\n",
    "        first_name = temp[0]\n",
    "\n",
    "        img = cv2.imread(path + first_name + '.jpg')\n",
    "        height, width, channels = img.shape\n",
    "\n",
    "        reading_file = open(path + first_name + '.txt',\"r\")\n",
    "        new_str = ''\n",
    "\n",
    "        for line in reading_file:\n",
    "            \n",
    "            words = (line.split())\n",
    "            size = (width, height)\n",
    "            box = [float(words[1]), float(words[2]), float(words[3]), float(words[4])]\n",
    "\n",
    "            x1, y1, x2, y2 = xywh2xyxy(size, np.array(box))\n",
    "\n",
    "            if y1 - ((y2 - y1) * ratio) > 0 and y2 + ((y2 - y1) * ratio) < height and x1 - ((x2 - x1) * ratio) > 0 and x2 + ((x2 - x1) * ratio) < width:\n",
    "                temp_x1 = x1 - ((ratio - 1) * x1)\n",
    "                temp_y1 = y1 - ((ratio - 1) * y1)\n",
    "                temp_x2 = x2 + ((ratio - 1) * x2)\n",
    "                temp_y2 = y2 + ((ratio - 1) * y2)\n",
    "\n",
    "                temp_box = [temp_x1, temp_y1, temp_x2, temp_y2]\n",
    "\n",
    "                new_x1, new_y1, new_x2, new_y2 = xyxyx2xywh(size=size, box=temp_box)\n",
    "\n",
    "                new_str += f'{words[0]} {new_x1} {new_y1} {new_x2} {new_y2}\\n'\n",
    "            \n",
    "            else:\n",
    "                print(first_name)\n",
    "                os.remove(path + first_name + '.jpg')\n",
    "                os.remove(path + first_name + '.txt')\n",
    "                break\n",
    "\n",
    "        writing_file = open(temp_destination + first_name + '.txt',\"w\")\n",
    "        writing_file.write(new_str)\n",
    "        writing_file.close()\n",
    "        \n",
    "        \n",
    "        cropped_image = img[int(temp_y1) : int(temp_y2), int(temp_x1) : int(temp_x2)]\n",
    "        cv2.imwrite(temp_destination + first_name + '.jpg', cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image cropping and annotation updating completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def crop_and_resize_images(txt_folder, image_dir, output_dir):\n",
    "    for txt_file_name in os.listdir(txt_folder):\n",
    "        count = 0\n",
    "        if txt_file_name.endswith('.txt'):\n",
    "            txt_file_path = os.path.join(txt_folder, txt_file_name)\n",
    "            with open(txt_file_path, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 5:\n",
    "                    continue\n",
    "                \n",
    "                class_id = int(parts[0])\n",
    "                x, y, width, height = map(float, parts[1:])\n",
    "\n",
    "                image_name = os.path.splitext(txt_file_name)[0] + '.jpg'\n",
    "                image_path = os.path.join(image_dir, image_name)\n",
    "                \n",
    "                if not os.path.exists(image_path):\n",
    "                    print(f\"Image {image_name} not found.\")\n",
    "                    continue\n",
    "                \n",
    "                image = cv2.imread(image_path)\n",
    "                if image is None:\n",
    "                    print(f\"Failed to load image: {image_path}\")\n",
    "                    continue\n",
    "                \n",
    "                image_height, image_width = image.shape[:2]\n",
    "                \n",
    "                x1 = int((x - width / 2) * image_width)\n",
    "                y1 = int((y - height / 2) * image_height)\n",
    "                x2 = int((x + width / 2) * image_width)\n",
    "                y2 = int((y + height / 2) * image_height)\n",
    "\n",
    "                x1 = max(0, min(x1, image_width - 1))\n",
    "                y1 = max(0, min(y1, image_height - 1))\n",
    "                x2 = max(0, min(x2, image_width - 1))\n",
    "                y2 = max(0, min(y2, image_height - 1))\n",
    "\n",
    "                padding_x = int((x2 - x1) * 0.7)\n",
    "                padding_y = int((y2 - y1) * 3.0)\n",
    "\n",
    "                x1 = max(0, x1 - padding_x)\n",
    "                y1 = max(0, y1 - padding_y)\n",
    "                x2 = min(image_width, x2 + padding_x)\n",
    "                y2 = min(image_height, y2 + padding_y)\n",
    "\n",
    "                cropped_image = image[y1:y2, x1:x2]\n",
    "\n",
    "                new_image_name = os.path.splitext(image_name)[0] + f'_{count}_cropped.jpg'\n",
    "                new_image_path = os.path.join(output_dir, new_image_name)\n",
    "                cv2.imwrite(new_image_path, cropped_image)\n",
    "                count += 1\n",
    "\n",
    "                new_x = (x - (x1 / image_width)) / ((x2 - x1) / image_width)\n",
    "                new_y = (y - (y1 / image_height)) / ((y2 - y1) / image_height)\n",
    "                new_width = width / ((x2 - x1) / image_width)\n",
    "                new_height = height / ((y2 - y1) / image_height)\n",
    "\n",
    "\n",
    "                new_txt_name = os.path.splitext(new_image_name)[0] + '.txt'\n",
    "                new_txt_path = os.path.join(output_dir, new_txt_name)\n",
    "                with open(new_txt_path, 'a') as new_txt_file:\n",
    "                    new_txt_file.write(f\"{class_id} {new_x} {new_y} {new_width} {new_height}\\n\")\n",
    "\n",
    "def main():\n",
    "    txt_folder = \"/home/bdogan/Downloads/deneme\"  # Path to the folder containing text files with bounding box annotations\n",
    "    image_dir = txt_folder  # Directory containing the images\n",
    "    output_dir = \"/home/bdogan/Downloads/temp/\"  # Output directory for cropped images and annotations\n",
    "\n",
    "    crop_and_resize_images(txt_folder, image_dir, output_dir)\n",
    "\n",
    "    print(\"Image cropping and annotation updating completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop image and move annotation to it's new place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def crop_image_and_update_labels(image_path, label_path, x1, y1, x2, y2, output_image_path, output_label_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    cropped_image = image[y1:y2, x1:x2]\n",
    "    cv2.imwrite(output_image_path, cropped_image)\n",
    "\n",
    "    with open(label_path, 'r') as f:\n",
    "        labels = f.readlines()\n",
    "\n",
    "    new_labels = []\n",
    "    for label in labels:\n",
    "        parts = label.strip().split()\n",
    "        class_id = parts[0]\n",
    "        bbox_x = float(parts[1]) * w\n",
    "        bbox_y = float(parts[2]) * h\n",
    "        bbox_w = float(parts[3]) * w\n",
    "        bbox_h = float(parts[4]) * h\n",
    "\n",
    "        new_x = (bbox_x - x1) / (x2 - x1)\n",
    "        new_y = (bbox_y - y1) / (y2 - y1)\n",
    "        new_w = bbox_w / (x2 - x1)\n",
    "        new_h = bbox_h / (y2 - y1)\n",
    "\n",
    "        if 0 <= new_x <= 1 and 0 <= new_y <= 1:\n",
    "            new_labels.append(f\"{class_id} {new_x} {new_y} {new_w} {new_h}\\n\")\n",
    "\n",
    "    with open(output_label_path, 'w') as f:\n",
    "        f.writelines(new_labels)\n",
    "\n",
    "def process_folder(input_folder, output_folder, x1, y1, x2, y2):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.jpg'):\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "            label_path = os.path.join(input_folder, filename.replace('.jpg', '.txt'))\n",
    "            output_image_path = os.path.join(output_folder, filename)\n",
    "            output_label_path = os.path.join(output_folder, filename.replace('.jpg', '.txt'))\n",
    "\n",
    "            if os.path.exists(label_path):\n",
    "                crop_image_and_update_labels(image_path, label_path, x1, y1, x2, y2, output_image_path, output_label_path)\n",
    "\n",
    "input_folder = '/home/bdogan/all_files/ekin_files/tbatuhanl/traffic_light_detection/cvat_sets_saha/000_ayrı_saha_3/temp'\n",
    "output_folder = '/home/bdogan/all_files/ekin_files/tbatuhanl/traffic_light_detection/cvat_sets_saha/000_ayrı_saha_3/1'\n",
    "x1, y1, x2, y2 = 677, 581, 791, 808\n",
    "\n",
    "process_folder(input_folder, output_folder, x1, y1, x2, y2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
